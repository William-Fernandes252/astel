{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>A simple, fast and reliable asyncronous web crawler for Python.</p> <ul> <li>Documentation: https://William-Fernandes252.github.io/astel</li> <li>GitHub: https://github.com/William-Fernandes252/astel</li> <li>PyPI: https://pypi.org/project/astel/</li> <li>Free software: MIT</li> </ul>"},{"location":"#features","title":"Features","text":"<p>The main goal of <code>astel</code> is to offer a simpler, efficient and performant solution to programmatically look for links  in webpages: no need to extend any class (composition over inheritance), no configuration and as few dependencies as possible.</p> <p>This package relies on HTTPX to send all requests in asynchronous operations, thus maximizing the number of pages processed during each execution.</p>"},{"location":"#credits","title":"Credits","text":"<p>This package was created with Cookiecutter and the waynerv/cookiecutter-pypackage project template.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#api-reference","title":"API Reference","text":""},{"location":"api/#astel.agent","title":"<code>astel.agent</code>","text":"<p>User agent for processing domain rules, thus allowing the crawler to fetch the pages without getting blocked.</p>"},{"location":"api/#astel.agent.UserAgent","title":"<code>UserAgent</code>","text":"<p>A user agent for processing domain rules so that the crawler can respect them.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the user agent</p> required Source code in <code>astel/agent.py</code> <pre><code>class UserAgent:\n    \"\"\"A user agent for processing domain rules so that the crawler can respect them.\n\n    Args:\n        name (str): The name of the user agent\n    \"\"\"\n\n    __slots__ = (\"name\", \"_acknowledged_domains\")\n\n    def __init__(self, name: str) -&gt; None:\n        self.name = name\n        self._acknowledged_domains: dict[str, RobotFileParser] = {}\n\n    def respect(self, domain: str, robots_txt: str) -&gt; None:\n        \"\"\"Process the rules in the robots.txt file in the URL and associates\n        them to the given domain, if the domain has not already been acknowledged.\n\n        Args:\n            domain (str): A string representing the domain to be acknowledged.\n            robots_txt (str): A string representing the content of the robots.txt file.\n        \"\"\"\n        if domain in self._acknowledged_domains:\n            return\n        parser = RobotFileParser()\n        parser.parse(robots_txt.splitlines())\n        self._acknowledged_domains[domain] = parser\n\n    def can_access(self, domain: str, url: str) -&gt; bool:\n        \"\"\"Determines whether the given URL can be accessed by the user agent for the specified domain.\n\n        Args:\n            domain (str): A string representing the domain of the URL.\n            url (str): A string representing the URL to access.\n\n        Returns:\n            bool: A boolean indicating whether the URL can be accessed for the specified domain.\n        \"\"\"  # noqa: E501\n        return self._acknowledged_domains[domain].can_fetch(self.name, url)\n\n    def get_request_rate(self, domain: str) -&gt; RequestRate | None:\n        \"\"\"Return the request rate of that domain if it is acknowledged.\n\n        Args:\n            domain (str): A string representing the domain whose request rate is sought.\n\n        Returns:\n            Union[RequestRate, None]: An instance of `RequestRate` representing the domain's request rate if the domain is acknowledged, else `None`.\n        \"\"\"  # noqa: E501\n        if domain not in self._acknowledged_domains:\n            return None\n        return self._acknowledged_domains[domain].request_rate(self.name)\n\n    def get_crawl_delay(self, domain: str) -&gt; str | None:\n        \"\"\"Return the crawl delay for the given domain if it has been acknowledged, and `None` otherwise.\n\n        Args:\n            domain (str): A string representing the domain to check the crawl delay for.\n\n        Returns:\n            Union[str, None]: A string representing the crawl delay for the given domain if it has been acknowledged, `None` otherwise.\n        \"\"\"  # noqa: E501\n        if domain not in self._acknowledged_domains:\n            return None\n\n        crawl_delay = self._acknowledged_domains[domain].crawl_delay(self.name)\n        return str(crawl_delay) if crawl_delay is not None else None\n\n    def get_site_maps(self, domain: str) -&gt; list[str] | None:\n        \"\"\"Return the site maps associated with the given domain if the domain is acknowledged, otherwise returns `None`.\n\n        Args:\n            domain (str): A string representing the domain to retrieve site maps for.\n\n        Returns:\n            Union[list[str], None]: A list of strings representing the site maps associated with the domain, or `None` if the domain is not acknowledged.\n        \"\"\"  # noqa: E501\n        if domain not in self._acknowledged_domains:\n            return None\n        return self._acknowledged_domains[domain].site_maps()\n\n    @property\n    def acknowledged_domains(self) -&gt; List[str]:\n        \"\"\"The domains that have been acknowledged by the user agent.\"\"\"\n        return list(self._acknowledged_domains.keys())\n</code></pre>"},{"location":"api/#astel.agent.UserAgent.acknowledged_domains","title":"<code>acknowledged_domains: List[str]</code>  <code>property</code>","text":"<p>The domains that have been acknowledged by the user agent.</p>"},{"location":"api/#astel.agent.UserAgent.can_access","title":"<code>can_access(domain, url)</code>","text":"<p>Determines whether the given URL can be accessed by the user agent for the specified domain.</p> <p>Parameters:</p> Name Type Description Default <code>domain</code> <code>str</code> <p>A string representing the domain of the URL.</p> required <code>url</code> <code>str</code> <p>A string representing the URL to access.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>A boolean indicating whether the URL can be accessed for the specified domain.</p> Source code in <code>astel/agent.py</code> <pre><code>def can_access(self, domain: str, url: str) -&gt; bool:\n    \"\"\"Determines whether the given URL can be accessed by the user agent for the specified domain.\n\n    Args:\n        domain (str): A string representing the domain of the URL.\n        url (str): A string representing the URL to access.\n\n    Returns:\n        bool: A boolean indicating whether the URL can be accessed for the specified domain.\n    \"\"\"  # noqa: E501\n    return self._acknowledged_domains[domain].can_fetch(self.name, url)\n</code></pre>"},{"location":"api/#astel.agent.UserAgent.get_crawl_delay","title":"<code>get_crawl_delay(domain)</code>","text":"<p>Return the crawl delay for the given domain if it has been acknowledged, and <code>None</code> otherwise.</p> <p>Parameters:</p> Name Type Description Default <code>domain</code> <code>str</code> <p>A string representing the domain to check the crawl delay for.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Union[str, None]: A string representing the crawl delay for the given domain if it has been acknowledged, <code>None</code> otherwise.</p> Source code in <code>astel/agent.py</code> <pre><code>def get_crawl_delay(self, domain: str) -&gt; str | None:\n    \"\"\"Return the crawl delay for the given domain if it has been acknowledged, and `None` otherwise.\n\n    Args:\n        domain (str): A string representing the domain to check the crawl delay for.\n\n    Returns:\n        Union[str, None]: A string representing the crawl delay for the given domain if it has been acknowledged, `None` otherwise.\n    \"\"\"  # noqa: E501\n    if domain not in self._acknowledged_domains:\n        return None\n\n    crawl_delay = self._acknowledged_domains[domain].crawl_delay(self.name)\n    return str(crawl_delay) if crawl_delay is not None else None\n</code></pre>"},{"location":"api/#astel.agent.UserAgent.get_request_rate","title":"<code>get_request_rate(domain)</code>","text":"<p>Return the request rate of that domain if it is acknowledged.</p> <p>Parameters:</p> Name Type Description Default <code>domain</code> <code>str</code> <p>A string representing the domain whose request rate is sought.</p> required <p>Returns:</p> Type Description <code>RequestRate | None</code> <p>Union[RequestRate, None]: An instance of <code>RequestRate</code> representing the domain's request rate if the domain is acknowledged, else <code>None</code>.</p> Source code in <code>astel/agent.py</code> <pre><code>def get_request_rate(self, domain: str) -&gt; RequestRate | None:\n    \"\"\"Return the request rate of that domain if it is acknowledged.\n\n    Args:\n        domain (str): A string representing the domain whose request rate is sought.\n\n    Returns:\n        Union[RequestRate, None]: An instance of `RequestRate` representing the domain's request rate if the domain is acknowledged, else `None`.\n    \"\"\"  # noqa: E501\n    if domain not in self._acknowledged_domains:\n        return None\n    return self._acknowledged_domains[domain].request_rate(self.name)\n</code></pre>"},{"location":"api/#astel.agent.UserAgent.get_site_maps","title":"<code>get_site_maps(domain)</code>","text":"<p>Return the site maps associated with the given domain if the domain is acknowledged, otherwise returns <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>domain</code> <code>str</code> <p>A string representing the domain to retrieve site maps for.</p> required <p>Returns:</p> Type Description <code>list[str] | None</code> <p>Union[list[str], None]: A list of strings representing the site maps associated with the domain, or <code>None</code> if the domain is not acknowledged.</p> Source code in <code>astel/agent.py</code> <pre><code>def get_site_maps(self, domain: str) -&gt; list[str] | None:\n    \"\"\"Return the site maps associated with the given domain if the domain is acknowledged, otherwise returns `None`.\n\n    Args:\n        domain (str): A string representing the domain to retrieve site maps for.\n\n    Returns:\n        Union[list[str], None]: A list of strings representing the site maps associated with the domain, or `None` if the domain is not acknowledged.\n    \"\"\"  # noqa: E501\n    if domain not in self._acknowledged_domains:\n        return None\n    return self._acknowledged_domains[domain].site_maps()\n</code></pre>"},{"location":"api/#astel.agent.UserAgent.respect","title":"<code>respect(domain, robots_txt)</code>","text":"<p>Process the rules in the robots.txt file in the URL and associates them to the given domain, if the domain has not already been acknowledged.</p> <p>Parameters:</p> Name Type Description Default <code>domain</code> <code>str</code> <p>A string representing the domain to be acknowledged.</p> required <code>robots_txt</code> <code>str</code> <p>A string representing the content of the robots.txt file.</p> required Source code in <code>astel/agent.py</code> <pre><code>def respect(self, domain: str, robots_txt: str) -&gt; None:\n    \"\"\"Process the rules in the robots.txt file in the URL and associates\n    them to the given domain, if the domain has not already been acknowledged.\n\n    Args:\n        domain (str): A string representing the domain to be acknowledged.\n        robots_txt (str): A string representing the content of the robots.txt file.\n    \"\"\"\n    if domain in self._acknowledged_domains:\n        return\n    parser = RobotFileParser()\n    parser.parse(robots_txt.splitlines())\n    self._acknowledged_domains[domain] = parser\n</code></pre>"},{"location":"api/#astel.crawler","title":"<code>astel.crawler</code>","text":"<p>Crawler module.</p> <p>This module defines the <code>Crawler</code> class that can be used to crawl websites asynchronously.</p>"},{"location":"api/#astel.crawler.Crawler","title":"<code>Crawler</code>","text":"<p>An asynchronous web crawler that can be used to extract, process and follow links in webpages.</p> <p>Parameters:</p> Name Type Description Default <code>urls</code> <code>Iterable[str]</code> <p>The URLs to start the crawler with.</p> required <code>options</code> <code>CrawlerOptions</code> <p>The options to use for the crawler.</p> <code>None</code> Source code in <code>astel/crawler.py</code> <pre><code>class Crawler:\n    \"\"\"An asynchronous web crawler that can be used to extract, process and follow links in webpages.\n\n    Args:\n        urls (Iterable[str]): The URLs to start the crawler with.\n        options (CrawlerOptions, optional): The options to use for the crawler.\n    \"\"\"  # noqa: E501\n\n    _todo: asyncio.Queue[asyncio.Task]\n    _client: httpx.AsyncClient\n    _start_urls: Set[str]\n    _urls_seen: Set[parsers.Url]\n    _done: Set[str]\n    _parser_class: Type[parsers.Parser]\n    _agent: agent.UserAgent\n    _rate_limiter: limiters.RateLimiter\n    _num_workers: int\n    _limit: int\n    _total_pages: int\n    _filters: List[filters.CallableFilter]\n    _event_emitter: events.EventEmitter\n    _workers: List[asyncio.Task]\n    _options: CrawlerOptions\n    _must_retry: RetryHandler | None\n\n    def __init__(\n        self, urls: Iterable[str], options: CrawlerOptions | None = None\n    ) -&gt; None:\n        self._todo: asyncio.Queue[asyncio.Task] = asyncio.Queue()\n        self._start_urls = set(urls)\n        self._urls_seen: set[parsers.Url] = set()\n        self._done: set[str] = set()\n        self._filters: List[filters.Filter] = []\n        self._options = merge_with_default_options(options)\n        self._client = self._options[\"client\"]\n        self._parser_class = self._options[\"parser_class\"]\n        self._agent = agent.UserAgent(self._options[\"user_agent\"])\n        self._rate_limiter = self._options[\"rate_limiter\"]\n        self._num_workers = self._options[\"workers\"]\n        self._limit = self._options[\"limit\"]\n        self._total_pages = 0\n        self._event_emitter = self._options[\"event_emitter_factory\"]()\n\n        def _must_retry(\n            url: parsers.Url, response: Union[httpx.Response, None], _: Crawler\n        ) -&gt; bool:\n            return bool(\n                (\n                    response\n                    and response.status_code in self._options[\"retry_for_status_codes\"]\n                )\n                and url\n            )\n\n        self._must_retry = (\n            cast(RetryHandler, _must_retry)\n            if self._options[\"retry_for_status_codes\"]\n            else None\n        )\n\n    async def run(self) -&gt; None:\n        \"\"\"Run the crawler.\"\"\"\n        await self._on_found_links({parsers.parse_url(url) for url in self._start_urls})\n\n        self._workers = [\n            asyncio.create_task(self._worker()) for _ in range(self._num_workers)\n        ]\n        await self._todo.join()\n\n        for worker in self._workers:\n            worker.cancel()\n\n    async def _worker(self) -&gt; None:\n        while True:\n            try:\n                await self._process_one()\n            except asyncio.CancelledError:\n                return\n\n    async def _process_one(self) -&gt; None:\n        task = await self._todo.get()\n        try:\n            await task\n        except httpx.HTTPError as e:\n            self._emit_event(events.Event.ERROR, e)\n            if self._must_retry and self._must_retry(\n                parsers.parse_url(str(e.request.url)),\n                getattr(e, \"response\", None),\n                self,\n            ):\n                await self._put_todo(parsers.parse_url(str(e.request.url)))\n        finally:\n            self._todo.task_done()\n\n    async def _crawl(self, url: parsers.Url) -&gt; None:\n        await self._rate_limiter.limit(url.raw)\n\n        if self._agent.can_access(url.domain, url.raw):\n            response = await self._send_request(url)\n            self._emit_event(events.Event.RESPONSE, response)\n            await self._on_found_links(\n                await self._parse_links(\n                    base=str(response.url),\n                    text=response.text,\n                )\n            )\n\n        self._done.add(url.raw)\n        self._emit_event(events.Event.DONE, url)\n\n    async def _send_request(self, url: parsers.Url) -&gt; httpx.Response:\n        request = httpx.Request(\n            \"GET\", url.raw, headers={\"User-Agent\": self._agent.name}\n        )\n        self._emit_event(events.Event.REQUEST, request)\n        return (\n            await self._client.send(request, follow_redirects=True)\n        ).raise_for_status()\n\n    async def _parse_links(self, base: str, text: str) -&gt; set[parsers.Url]:\n        parser = self._parser_class(base=base)\n        parser.feed(text)\n        return {link for link in parser.found_links if self._apply_filters(link)}\n\n    def _apply_filters(self, url: parsers.Url) -&gt; bool:\n        return all(f(url) for f in self._filters)\n\n    async def _acknowledge_domains(\n        self, parsed_urls: set[parsers.Url]\n    ) -&gt; set[parsers.Url]:\n        new = parsed_urls - self._urls_seen\n        for result in new:\n            robots_txt = (\n                (\n                    await self._client.get(\n                        f\"{result.scheme}://{result.domain}/robots.txt\",\n                        timeout=5,\n                        follow_redirects=False,\n                        headers={\n                            \"User-Agent\": self._agent.name,\n                            \"Accept\": \"text/plain\",\n                        },\n                    )\n                )\n                .raise_for_status()\n                .text\n            )\n            self._agent.respect(result.domain, robots_txt)\n\n            tasks = [\n                asyncio.create_task(\n                    self._acknowledge_domains(await self.parse_site_map(site_map_path))\n                )\n                for site_map_path in self._agent.get_site_maps(result.domain) or []\n            ]\n            if len(tasks) &gt; 0:\n                done, _ = await asyncio.wait(tasks)\n                for future in done:\n                    task_result = future.result()\n                    if isinstance(task_result, set):\n                        new.update(future.result())\n                    else:\n                        raise cast(BaseException, task_result)\n\n            self._rate_limiter.configure(\n                {\n                    \"domain\": result.domain,\n                    \"crawl_delay\": self._agent.get_crawl_delay(result.domain),\n                    \"request_rate\": self._agent.get_request_rate(result.domain),\n                }\n            )\n\n        self._urls_seen.update(new)\n\n        return new\n\n    async def parse_site_map(self, site_map_path: str) -&gt; Set[parsers.Url]:\n        \"\"\"Parse a sitemap.xml file and return the URLs found in it.\n\n        Args:\n            site_map_path (str): The URL of the sitemap.xml file.\n\n        Returns:\n            Set[parsers.Url]: The URLs found in the sitemap.xml file.\n        \"\"\"\n        parser = parsers.SiteMapParser(site_map_path)\n        response = (await self._client.get(site_map_path)).raise_for_status()\n        parser.feed(response.text)\n        return parser.found_links\n\n    def filter(self, *args: filters.CallableFilter, **kwargs) -&gt; Self:\n        \"\"\"Add URL filters to the crawler.\n\n        Filters can be used to determine which URLs should be ignored.\n\n        Args:\n            *args (Filter): A list of `Filter` objects to add to the crawler.\n            **kwargs (Any): A list of keyword arguments to create `Filter` objects from.\n\n        Returns:\n            Crawler: The `Crawler` object with the added filters.\n\n        Raises:\n            ValueError: If a filter could not be created from the given keyword arguments.\n\n        Examples:\n            &gt;&gt;&gt; crawler.filter(filters.StartsWith(\"scheme\", \"http\"))\n            &gt;&gt;&gt; crawler.filter(filters.Matches(\"https://example.com\"))\n            &gt;&gt;&gt; crawler.filter(domain__in=[\"example.com\"])\n        \"\"\"  # noqa: E501\n        self._filters.extend(\n            [\n                *args,\n                *[\n                    f\n                    for f in (\n                        filters.create_from_kwarg(key, value)\n                        for key, value in kwargs.items()\n                    )\n                    if f is not None\n                ],\n            ],\n        )\n        return self\n\n    async def _on_found_links(self, urls: set[parsers.Url]) -&gt; None:\n        for url in urls:\n            self._emit_event(events.Event.URL_FOUND, url)\n        for url in await self._acknowledge_domains(urls):\n            await self._put_todo(url)\n\n    async def _put_todo(self, url: parsers.Url) -&gt; None:\n        if self._total_pages &gt; self._limit:\n            return\n        self._total_pages += 1\n        await self._todo.put(asyncio.create_task(self._crawl(url)))\n\n    def on(self, event: events.Event, handler: events.Handler) -&gt; Self:\n        \"\"\"Add an event handler to the crawler.\n\n        An event is emitted when\n        - a request is ready to be sent (`Event.REQUEST`): the `httpx.Request` object is\n        passed to the handler.\n        - a response is received (`Event.RESPONSE`): the `httpx.Response` object is\n        passed to the handler.\n        - an error occurs (`Event.ERROR`): the `Error` object is passed to the handler.\n        - a URL is done being processed (`Event.DONE`): the `astel.parsers.Url` object\n        is passed to the handler.\n        - a URL is found in a page (`Event.URL_FOUND`): the `astel.parsers.Url` object is passed to the handler.\n\n        Args:\n            event (str): The event to add the handler to.\n            handler (Callable): The handler to add to the event.\n        \"\"\"  # noqa: E501\n        self._event_emitter.on(event, handler)\n        return self\n\n    def _emit_event(self, event: events.Event, *data) -&gt; None:\n        self._event_emitter.emit(event, *data, crawler=self)\n\n    def stop(self, *, reset: bool = False) -&gt; None:\n        \"\"\"Stop the crawler current execution.\n\n        Args:\n            reset (bool, optional: Optionally, reset the crawler on the same call. Defaults to `False`.\n        \"\"\"  # noqa: E501\n        for worker in self._workers:\n            worker.cancel()\n        if reset:\n            self.reset()\n\n    def reset(self) -&gt; None:\n        \"\"\"Reset the crawler.\"\"\"\n        self._done.clear()\n        self._urls_seen.clear()\n        self._total_pages = 0\n\n    def retry(self, handler: RetryHandler) -&gt; Self:\n        \"\"\"Set a handler to determine whether a request should be retried.\n\n        Args:\n            handler (Callable): A function that takes a `httpx.Response` and a `astel.parsers.Url` object and returns a boolean indicating whether the request should be retried.\n\n        Returns:\n            Crawler: The `Crawler` object with the retry handler set.\n        \"\"\"  # noqa: E501\n        self._must_retry = handler\n        return self\n\n    @property\n    def total_pages(self) -&gt; int:\n        \"\"\"The total number of pages queued by the crawler.\"\"\"\n        return self._total_pages\n\n    @property\n    def done(self) -&gt; set[str]:\n        \"\"\"The URLs that have been crawled by the crawler.\"\"\"\n        return self._done\n\n    @property\n    def urls_seen(self) -&gt; set[parsers.Url]:\n        \"\"\"The URLs that have been seen by the crawler.\"\"\"\n        return self._urls_seen\n\n    @property\n    def rate_limiter(self) -&gt; limiters.RateLimiter:\n        \"\"\"The rate limiter used by the crawler.\"\"\"\n        return self._rate_limiter\n\n    @property\n    def num_workers(self) -&gt; int:\n        \"\"\"The number of worker tasks used by the crawler.\"\"\"\n        return self._num_workers\n\n    @property\n    def limit(self) -&gt; int:\n        \"\"\"The maximum number of pages to crawl.\n\n        It is used as a fail-safe to prevent the crawler from running indefinitely.\n        \"\"\"\n        return self._limit\n\n    @property\n    def parser_class(self) -&gt; Type[parsers.Parser]:\n        \"\"\"The parser factory object used by the crawler to parse HTML responses.\"\"\"\n        return self._parser_class\n\n    @property\n    def start_urls(self) -&gt; Set[str]:\n        \"\"\"The URLs that the crawler was started with.\"\"\"\n        return self._start_urls\n\n    @property\n    def agent(self) -&gt; str:\n        \"\"\"The user agent used by the crawler.\"\"\"\n        return self._agent.name\n\n    @property\n    def options(self) -&gt; CrawlerOptions:\n        \"\"\"The options used by the crawler.\"\"\"\n        return self._options\n\n    @options.setter\n    def options(self, options: Optional[CrawlerOptions] = None) -&gt; None:\n        \"\"\"Set the options used by the crawler.\"\"\"\n        self._options = merge_with_default_options(options)\n        self._client = self._options[\"client\"]\n        self._agent = agent.UserAgent(self._options[\"user_agent\"])\n        self._rate_limiter = self._options[\"rate_limiter\"]\n        self._num_workers = self._options[\"workers\"]\n        self._limit = self._options[\"limit\"]\n        self._parser_class = self._options[\"parser_class\"]\n        self._event_emitter = self._options[\"event_emitter_factory\"]()\n</code></pre>"},{"location":"api/#astel.crawler.Crawler.agent","title":"<code>agent: str</code>  <code>property</code>","text":"<p>The user agent used by the crawler.</p>"},{"location":"api/#astel.crawler.Crawler.done","title":"<code>done: set[str]</code>  <code>property</code>","text":"<p>The URLs that have been crawled by the crawler.</p>"},{"location":"api/#astel.crawler.Crawler.limit","title":"<code>limit: int</code>  <code>property</code>","text":"<p>The maximum number of pages to crawl.</p> <p>It is used as a fail-safe to prevent the crawler from running indefinitely.</p>"},{"location":"api/#astel.crawler.Crawler.num_workers","title":"<code>num_workers: int</code>  <code>property</code>","text":"<p>The number of worker tasks used by the crawler.</p>"},{"location":"api/#astel.crawler.Crawler.options","title":"<code>options: CrawlerOptions</code>  <code>property</code> <code>writable</code>","text":"<p>The options used by the crawler.</p>"},{"location":"api/#astel.crawler.Crawler.parser_class","title":"<code>parser_class: Type[parsers.Parser]</code>  <code>property</code>","text":"<p>The parser factory object used by the crawler to parse HTML responses.</p>"},{"location":"api/#astel.crawler.Crawler.rate_limiter","title":"<code>rate_limiter: limiters.RateLimiter</code>  <code>property</code>","text":"<p>The rate limiter used by the crawler.</p>"},{"location":"api/#astel.crawler.Crawler.start_urls","title":"<code>start_urls: Set[str]</code>  <code>property</code>","text":"<p>The URLs that the crawler was started with.</p>"},{"location":"api/#astel.crawler.Crawler.total_pages","title":"<code>total_pages: int</code>  <code>property</code>","text":"<p>The total number of pages queued by the crawler.</p>"},{"location":"api/#astel.crawler.Crawler.urls_seen","title":"<code>urls_seen: set[parsers.Url]</code>  <code>property</code>","text":"<p>The URLs that have been seen by the crawler.</p>"},{"location":"api/#astel.crawler.Crawler.filter","title":"<code>filter(*args, **kwargs)</code>","text":"<p>Add URL filters to the crawler.</p> <p>Filters can be used to determine which URLs should be ignored.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Filter</code> <p>A list of <code>Filter</code> objects to add to the crawler.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>A list of keyword arguments to create <code>Filter</code> objects from.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Crawler</code> <code>Self</code> <p>The <code>Crawler</code> object with the added filters.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a filter could not be created from the given keyword arguments.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; crawler.filter(filters.StartsWith(\"scheme\", \"http\"))\n&gt;&gt;&gt; crawler.filter(filters.Matches(\"https://example.com\"))\n&gt;&gt;&gt; crawler.filter(domain__in=[\"example.com\"])\n</code></pre> Source code in <code>astel/crawler.py</code> <pre><code>def filter(self, *args: filters.CallableFilter, **kwargs) -&gt; Self:\n    \"\"\"Add URL filters to the crawler.\n\n    Filters can be used to determine which URLs should be ignored.\n\n    Args:\n        *args (Filter): A list of `Filter` objects to add to the crawler.\n        **kwargs (Any): A list of keyword arguments to create `Filter` objects from.\n\n    Returns:\n        Crawler: The `Crawler` object with the added filters.\n\n    Raises:\n        ValueError: If a filter could not be created from the given keyword arguments.\n\n    Examples:\n        &gt;&gt;&gt; crawler.filter(filters.StartsWith(\"scheme\", \"http\"))\n        &gt;&gt;&gt; crawler.filter(filters.Matches(\"https://example.com\"))\n        &gt;&gt;&gt; crawler.filter(domain__in=[\"example.com\"])\n    \"\"\"  # noqa: E501\n    self._filters.extend(\n        [\n            *args,\n            *[\n                f\n                for f in (\n                    filters.create_from_kwarg(key, value)\n                    for key, value in kwargs.items()\n                )\n                if f is not None\n            ],\n        ],\n    )\n    return self\n</code></pre>"},{"location":"api/#astel.crawler.Crawler.on","title":"<code>on(event, handler)</code>","text":"<p>Add an event handler to the crawler.</p> <p>An event is emitted when - a request is ready to be sent (<code>Event.REQUEST</code>): the <code>httpx.Request</code> object is passed to the handler. - a response is received (<code>Event.RESPONSE</code>): the <code>httpx.Response</code> object is passed to the handler. - an error occurs (<code>Event.ERROR</code>): the <code>Error</code> object is passed to the handler. - a URL is done being processed (<code>Event.DONE</code>): the <code>astel.parsers.Url</code> object is passed to the handler. - a URL is found in a page (<code>Event.URL_FOUND</code>): the <code>astel.parsers.Url</code> object is passed to the handler.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>str</code> <p>The event to add the handler to.</p> required <code>handler</code> <code>Callable</code> <p>The handler to add to the event.</p> required Source code in <code>astel/crawler.py</code> <pre><code>def on(self, event: events.Event, handler: events.Handler) -&gt; Self:\n    \"\"\"Add an event handler to the crawler.\n\n    An event is emitted when\n    - a request is ready to be sent (`Event.REQUEST`): the `httpx.Request` object is\n    passed to the handler.\n    - a response is received (`Event.RESPONSE`): the `httpx.Response` object is\n    passed to the handler.\n    - an error occurs (`Event.ERROR`): the `Error` object is passed to the handler.\n    - a URL is done being processed (`Event.DONE`): the `astel.parsers.Url` object\n    is passed to the handler.\n    - a URL is found in a page (`Event.URL_FOUND`): the `astel.parsers.Url` object is passed to the handler.\n\n    Args:\n        event (str): The event to add the handler to.\n        handler (Callable): The handler to add to the event.\n    \"\"\"  # noqa: E501\n    self._event_emitter.on(event, handler)\n    return self\n</code></pre>"},{"location":"api/#astel.crawler.Crawler.parse_site_map","title":"<code>parse_site_map(site_map_path)</code>  <code>async</code>","text":"<p>Parse a sitemap.xml file and return the URLs found in it.</p> <p>Parameters:</p> Name Type Description Default <code>site_map_path</code> <code>str</code> <p>The URL of the sitemap.xml file.</p> required <p>Returns:</p> Type Description <code>Set[Url]</code> <p>Set[parsers.Url]: The URLs found in the sitemap.xml file.</p> Source code in <code>astel/crawler.py</code> <pre><code>async def parse_site_map(self, site_map_path: str) -&gt; Set[parsers.Url]:\n    \"\"\"Parse a sitemap.xml file and return the URLs found in it.\n\n    Args:\n        site_map_path (str): The URL of the sitemap.xml file.\n\n    Returns:\n        Set[parsers.Url]: The URLs found in the sitemap.xml file.\n    \"\"\"\n    parser = parsers.SiteMapParser(site_map_path)\n    response = (await self._client.get(site_map_path)).raise_for_status()\n    parser.feed(response.text)\n    return parser.found_links\n</code></pre>"},{"location":"api/#astel.crawler.Crawler.reset","title":"<code>reset()</code>","text":"<p>Reset the crawler.</p> Source code in <code>astel/crawler.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"Reset the crawler.\"\"\"\n    self._done.clear()\n    self._urls_seen.clear()\n    self._total_pages = 0\n</code></pre>"},{"location":"api/#astel.crawler.Crawler.retry","title":"<code>retry(handler)</code>","text":"<p>Set a handler to determine whether a request should be retried.</p> <p>Parameters:</p> Name Type Description Default <code>handler</code> <code>Callable</code> <p>A function that takes a <code>httpx.Response</code> and a <code>astel.parsers.Url</code> object and returns a boolean indicating whether the request should be retried.</p> required <p>Returns:</p> Name Type Description <code>Crawler</code> <code>Self</code> <p>The <code>Crawler</code> object with the retry handler set.</p> Source code in <code>astel/crawler.py</code> <pre><code>def retry(self, handler: RetryHandler) -&gt; Self:\n    \"\"\"Set a handler to determine whether a request should be retried.\n\n    Args:\n        handler (Callable): A function that takes a `httpx.Response` and a `astel.parsers.Url` object and returns a boolean indicating whether the request should be retried.\n\n    Returns:\n        Crawler: The `Crawler` object with the retry handler set.\n    \"\"\"  # noqa: E501\n    self._must_retry = handler\n    return self\n</code></pre>"},{"location":"api/#astel.crawler.Crawler.run","title":"<code>run()</code>  <code>async</code>","text":"<p>Run the crawler.</p> Source code in <code>astel/crawler.py</code> <pre><code>async def run(self) -&gt; None:\n    \"\"\"Run the crawler.\"\"\"\n    await self._on_found_links({parsers.parse_url(url) for url in self._start_urls})\n\n    self._workers = [\n        asyncio.create_task(self._worker()) for _ in range(self._num_workers)\n    ]\n    await self._todo.join()\n\n    for worker in self._workers:\n        worker.cancel()\n</code></pre>"},{"location":"api/#astel.crawler.Crawler.stop","title":"<code>stop(*, reset=False)</code>","text":"<p>Stop the crawler current execution.</p> <p>Parameters:</p> Name Type Description Default <code>reset</code> <code>bool</code> <p>Optionally, reset the crawler on the same call. Defaults to <code>False</code>.</p> <code>False</code> Source code in <code>astel/crawler.py</code> <pre><code>def stop(self, *, reset: bool = False) -&gt; None:\n    \"\"\"Stop the crawler current execution.\n\n    Args:\n        reset (bool, optional: Optionally, reset the crawler on the same call. Defaults to `False`.\n    \"\"\"  # noqa: E501\n    for worker in self._workers:\n        worker.cancel()\n    if reset:\n        self.reset()\n</code></pre>"},{"location":"api/#astel.errors","title":"<code>astel.errors</code>","text":""},{"location":"api/#astel.errors.Error","title":"<code>Error</code>","text":"<p>             Bases: <code>Exception</code></p> <p>Base class for exceptions in this package</p> Source code in <code>astel/errors.py</code> <pre><code>class Error(Exception):\n    \"\"\"\n    Base class for exceptions in this package\n    \"\"\"\n\n    default_message: str | None = None\n\n    def __init__(self, message: str = \"\") -&gt; None:\n        super().__init__(message)\n        self.message = message or self.default_message\n\n    def __repr__(self) -&gt; str:\n        return f\"{self.__class__.__name__}({self.message})\"\n</code></pre>"},{"location":"api/#astel.errors.InvalidConfigurationError","title":"<code>InvalidConfigurationError</code>","text":"<p>             Bases: <code>Error</code></p> <p>Raised when a rate limiter configure call is invalid</p> Source code in <code>astel/errors.py</code> <pre><code>class InvalidConfigurationError(Error):\n    \"\"\"\n    Raised when a rate limiter configure call is invalid\n    \"\"\"\n\n    default_message = (\n        \"Invalid configuration. A crawl delay or a request rate must be given.\"\n    )\n</code></pre>"},{"location":"api/#astel.errors.InvalidUrlError","title":"<code>InvalidUrlError</code>","text":"<p>             Bases: <code>Error</code></p> <p>Raised when a URL is invalid</p> Source code in <code>astel/errors.py</code> <pre><code>class InvalidUrlError(Error):\n    \"\"\"\n    Raised when a URL is invalid\n    \"\"\"\n\n    def __init__(self, url: str) -&gt; None:\n        super().__init__(f'The URL \"{url}\" is invalid.')\n        self.url = url\n</code></pre>"},{"location":"api/#astel.events","title":"<code>astel.events</code>","text":"<p>Event handlers for the crawler.</p> <p>This module defines the event handlers that can be used to do some action when a specific event occurs, like storing information about the pages crawled, logging errors, or stopping the execution. The handlers are called with the current <code>Crawler</code> instance (passed through the <code>crawler</code> kwarg) and the event data.</p>"},{"location":"api/#astel.events.DoneHandler","title":"<code>DoneHandler</code>","text":"<p>             Bases: <code>Protocol</code></p> <p>Handler for when a crawler finishes processing a URL.</p> Source code in <code>astel/events.py</code> <pre><code>class DoneHandler(Protocol):\n    \"\"\"Handler for when a crawler finishes processing a URL.\"\"\"\n\n    def __call__(self, url: parsers.Url, crawler: \"Crawler\") -&gt; None: ...\n</code></pre>"},{"location":"api/#astel.events.ErrorHandler","title":"<code>ErrorHandler</code>","text":"<p>             Bases: <code>Protocol</code></p> <p>Handler for errors occurred during a crawler execution.</p> Source code in <code>astel/events.py</code> <pre><code>class ErrorHandler(Protocol):\n    \"\"\"Handler for errors occurred during a crawler execution.\"\"\"\n\n    def __call__(\n        self, error: errors.Error, crawler: \"Crawler\", *, reraise: bool = False\n    ) -&gt; None: ...\n</code></pre>"},{"location":"api/#astel.events.EventEmitter","title":"<code>EventEmitter</code>","text":"<p>             Bases: <code>Protocol</code></p> <p>Protocol for an event emitter.</p> Source code in <code>astel/events.py</code> <pre><code>class EventEmitter(Protocol):\n    \"\"\"Protocol for an event emitter.\"\"\"\n\n    def emit(\n        self,\n        event: Event,\n        *data: Union[httpx.Request, httpx.Response, errors.Error, parsers.Url],\n        crawler: \"Crawler\",\n    ) -&gt; Self: ...\n\n    def on(self, event: Event, handler: Handler) -&gt; Self: ...\n</code></pre>"},{"location":"api/#astel.events.RequestHandler","title":"<code>RequestHandler</code>","text":"<p>             Bases: <code>Protocol</code></p> <p>Handler for requests made by a crawler.</p> Source code in <code>astel/events.py</code> <pre><code>class RequestHandler(Protocol):\n    \"\"\"Handler for requests made by a crawler.\"\"\"\n\n    def __call__(self, request: httpx.Request, crawler: \"Crawler\") -&gt; None: ...\n</code></pre>"},{"location":"api/#astel.events.ResponseHandler","title":"<code>ResponseHandler</code>","text":"<p>             Bases: <code>Protocol</code></p> <p>Handler for responses received by a crawler.</p> Source code in <code>astel/events.py</code> <pre><code>class ResponseHandler(Protocol):\n    \"\"\"Handler for responses received by a crawler.\"\"\"\n\n    def __call__(self, response: httpx.Response, crawler: \"Crawler\") -&gt; None: ...\n</code></pre>"},{"location":"api/#astel.events.UrlFoundHandler","title":"<code>UrlFoundHandler</code>","text":"<p>             Bases: <code>Protocol</code></p> <p>Handler for when a URL is found in a page.</p> Source code in <code>astel/events.py</code> <pre><code>class UrlFoundHandler(Protocol):\n    \"\"\"Handler for when a URL is found in a page.\"\"\"\n\n    def __call__(self, url: parsers.Url, crawler: \"Crawler\") -&gt; None: ...\n</code></pre>"},{"location":"api/#astel.filters","title":"<code>astel.filters</code>","text":"<p>Filters for URLs.</p> <p>Some URLs in a webpage may not be relevant to your use cases.</p> <p>This module defines the filters that can be used to filter out URLs from the crawlers execution based on their properties.</p>"},{"location":"api/#astel.filters.CallableFilter","title":"<code>CallableFilter</code>","text":"<p>             Bases: <code>Protocol</code></p> <p>Callable filter interface.</p> Source code in <code>astel/filters.py</code> <pre><code>class CallableFilter(Protocol):\n    \"\"\"Callable filter interface.\"\"\"\n\n    def __call__(self, url: Url) -&gt; bool: ...\n</code></pre>"},{"location":"api/#astel.filters.Contains","title":"<code>Contains</code>","text":"<p>             Bases: <code>TextFilter</code></p> <p>Filter URLs based on a text substring.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from astel.filterers.filters import Contains\n&gt;&gt;&gt; domain_contains = Contains(\"domain\", \"example\")\n&gt;&gt;&gt; domain_contains.filter(ParsedUrl(domain=\"https://example.com\", ...))  # True\n</code></pre> Source code in <code>astel/filters.py</code> <pre><code>class Contains(TextFilter):\n    \"\"\"Filter URLs based on a text substring.\n\n    Examples:\n        &gt;&gt;&gt; from astel.filterers.filters import Contains\n        &gt;&gt;&gt; domain_contains = Contains(\"domain\", \"example\")\n        &gt;&gt;&gt; domain_contains.filter(ParsedUrl(domain=\"https://example.com\", ...))  # True\n    \"\"\"\n\n    def _apply(self, url: Url) -&gt; bool:\n        return self.text in self._get_url_property(url)\n</code></pre>"},{"location":"api/#astel.filters.EndsWith","title":"<code>EndsWith</code>","text":"<p>             Bases: <code>TextFilter</code></p> <p>Filter URLs based on a text suffix.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from astel.filterers.filters import EndsWith\n&gt;&gt;&gt; domain_ends_with = EndsWith(\"domain\", \".com\")\n&gt;&gt;&gt; domain_ends_with.filter(ParsedUrl(domain=\"https://example.com\", ...))  # True\n</code></pre> Source code in <code>astel/filters.py</code> <pre><code>class EndsWith(TextFilter):\n    \"\"\"Filter URLs based on a text suffix.\n\n    Examples:\n        &gt;&gt;&gt; from astel.filterers.filters import EndsWith\n        &gt;&gt;&gt; domain_ends_with = EndsWith(\"domain\", \".com\")\n        &gt;&gt;&gt; domain_ends_with.filter(ParsedUrl(domain=\"https://example.com\", ...))  # True\n    \"\"\"  # noqa: E501\n\n    def _apply(self, url: Url) -&gt; bool:\n        return self._get_url_property(url).endswith(self.text)\n</code></pre>"},{"location":"api/#astel.filters.Filter","title":"<code>Filter</code>","text":"<p>             Bases: <code>ABC</code>, <code>Generic[T]</code></p> <p>Base class for filters.</p> <p>Filters are used to determine if a URL should be processed or not. They can be combined using the bitwise operator <code>&amp;</code>: <code>filter1</code> &amp; <code>filter2</code> will return a new filter that will pass only if both <code>filter1</code> and <code>filter2</code> pass.</p> <p>New filters can be created by subclassing this class and implementing the <code>_apply</code> method.</p> Generic <p>Examples:</p> <pre><code>&gt;&gt;&gt; from astel.filterers.filters import In\n&gt;&gt;&gt; domain_in_list = In(\"domain\", [\"example.com\"])\n&gt;&gt;&gt; html_or_php = In(lambda url: url.path.split(\".\")[-1], [\"html\", \"php\"])\n&gt;&gt;&gt; my_filter = domain_in_list &amp; html_or_php\n</code></pre> Source code in <code>astel/filters.py</code> <pre><code>class Filter(ABC, Generic[T]):\n    \"\"\"\n    Base class for filters.\n\n    Filters are used to determine if a URL should be processed or not. They can be combined using the bitwise operator `&amp;`: `filter1` &amp; `filter2` will return a new filter that will pass only if both `filter1` and `filter2` pass.\n\n    New filters can be created by subclassing this class and implementing the `_apply` method.\n\n    Generic:\n        T: The type of the filter parameter.\n\n    Examples:\n        &gt;&gt;&gt; from astel.filterers.filters import In\n        &gt;&gt;&gt; domain_in_list = In(\"domain\", [\"example.com\"])\n        &gt;&gt;&gt; html_or_php = In(lambda url: url.path.split(\".\")[-1], [\"html\", \"php\"])\n        &gt;&gt;&gt; my_filter = domain_in_list &amp; html_or_php\n    \"\"\"  # noqa: E501\n\n    url_prop: UrlProperty\n    __inverted: bool\n    _chained: list[Filter]\n    param: T | None\n\n    def __init__(\n        self,\n        url_prop: UrlProperty,\n        param: T | None = None,\n        *,\n        _inverted: bool = False,\n        _chained: list[Filter] | None = None,\n    ) -&gt; None:\n        \"\"\"Initializes the filter with the given URL property.\"\"\"\n        self.param = param\n        self.url_prop = url_prop\n        self.__inverted = _inverted\n        self._chained = _chained or []\n\n    @abstractmethod\n    def _apply(self, url: Url) -&gt; bool:\n        \"\"\"Test the filter rule on the given URL.\n\n        Args:\n            url (Url): The URL to test the filter on.\n\n        Returns:\n            bool: True if the URL passes the filter, False otherwise.\n        \"\"\"\n        ...\n\n    def _get_url_property(self, url: Url) -&gt; str:\n        \"\"\"Return the URL property value for the given URL.\n\n        Args:\n            url (Url): The URL to get the property from.\n\n        Returns:\n            str: The URL property value.\n        \"\"\"\n        return getattr(url, self.url_prop)\n\n    def filter(self, url: Url) -&gt; bool:\n        \"\"\"Applies the filter to the given URL.\n\n        Args:\n            url (Url): The URL to filter.\n\n        Returns:\n            bool: True if the URL passes the filter, False otherwise.\n        \"\"\"\n        return all(\n            (\n                *(f.filter(url) for f in self._chained),\n                bool(self._apply(url) - self.__inverted),\n            )\n        )\n\n    def __call__(self, url: Url) -&gt; bool:\n        return self.filter(url)\n\n    def __invert__(self) -&gt; Filter:\n        new = copy.deepcopy(self)\n        new.__inverted = not self.__inverted  # noqa: SLF001\n        return new\n\n    def __and__(self, other: Filter) -&gt; Filter:\n        if not isinstance(other, Filter):\n            raise NotImplementedError\n        new = copy.deepcopy(self)\n        new._chained.append(other)\n        return new\n</code></pre>"},{"location":"api/#astel.filters.Filter.__init__","title":"<code>__init__(url_prop, param=None, *, _inverted=False, _chained=None)</code>","text":"<p>Initializes the filter with the given URL property.</p> Source code in <code>astel/filters.py</code> <pre><code>def __init__(\n    self,\n    url_prop: UrlProperty,\n    param: T | None = None,\n    *,\n    _inverted: bool = False,\n    _chained: list[Filter] | None = None,\n) -&gt; None:\n    \"\"\"Initializes the filter with the given URL property.\"\"\"\n    self.param = param\n    self.url_prop = url_prop\n    self.__inverted = _inverted\n    self._chained = _chained or []\n</code></pre>"},{"location":"api/#astel.filters.Filter.filter","title":"<code>filter(url)</code>","text":"<p>Applies the filter to the given URL.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>Url</code> <p>The URL to filter.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the URL passes the filter, False otherwise.</p> Source code in <code>astel/filters.py</code> <pre><code>def filter(self, url: Url) -&gt; bool:\n    \"\"\"Applies the filter to the given URL.\n\n    Args:\n        url (Url): The URL to filter.\n\n    Returns:\n        bool: True if the URL passes the filter, False otherwise.\n    \"\"\"\n    return all(\n        (\n            *(f.filter(url) for f in self._chained),\n            bool(self._apply(url) - self.__inverted),\n        )\n    )\n</code></pre>"},{"location":"api/#astel.filters.In","title":"<code>In</code>","text":"<p>             Bases: <code>Filter[Sequence[str]]</code></p> <p>Filter URLs based on a group of values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from astel.filterers.filters import In\n&gt;&gt;&gt; domain_in_list = In(\"domain\", [\"example.com\"])\n&gt;&gt;&gt; domain_in_list.filter(ParsedUrl(domain=\"https://example.com\", ...))  # True\n</code></pre> Source code in <code>astel/filters.py</code> <pre><code>class In(Filter[Sequence[str]]):\n    \"\"\"Filter URLs based on a group of values.\n\n    Examples:\n        &gt;&gt;&gt; from astel.filterers.filters import In\n        &gt;&gt;&gt; domain_in_list = In(\"domain\", [\"example.com\"])\n        &gt;&gt;&gt; domain_in_list.filter(ParsedUrl(domain=\"https://example.com\", ...))  # True\n    \"\"\"\n\n    def __init__(self, url_prop: UrlProperty, group: Sequence[str], **kwargs) -&gt; None:\n        super().__init__(url_prop, **kwargs)\n        self.set = set(group)\n\n    def _apply(self, url: Url) -&gt; bool:\n        return self._get_url_property(url) in self.set\n</code></pre>"},{"location":"api/#astel.filters.Matches","title":"<code>Matches</code>","text":"<p>             Bases: <code>Filter[Union[Pattern, str]]</code></p> <p>Filter URLs based on a regular expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from astel.filterers.filters import Matches\n&gt;&gt;&gt; domain_matches = Matches(\"domain\", r\"example\\..+\")\n&gt;&gt;&gt; domain_matches.filter(ParsedUrl(domain=\"https://example.com\", ...))  # True\n</code></pre> Source code in <code>astel/filters.py</code> <pre><code>class Matches(Filter[Union[re.Pattern, str]]):\n    r\"\"\"Filter URLs based on a regular expression.\n\n    Examples:\n        &gt;&gt;&gt; from astel.filterers.filters import Matches\n        &gt;&gt;&gt; domain_matches = Matches(\"domain\", r\"example\\..+\")\n        &gt;&gt;&gt; domain_matches.filter(ParsedUrl(domain=\"https://example.com\", ...))  # True\n    \"\"\"\n\n    def __init__(\n        self, url_prop: UrlProperty, regex: re.Pattern | str, **kwargs\n    ) -&gt; None:\n        super().__init__(url_prop, regex, **kwargs)\n        self.regex = re.compile(regex) if isinstance(regex, str) else regex\n\n    def _apply(self, url: Url) -&gt; bool:\n        return re.match(self.regex, self._get_url_property(url)) is not None\n</code></pre>"},{"location":"api/#astel.filters.StartsWith","title":"<code>StartsWith</code>","text":"<p>             Bases: <code>TextFilter</code></p> <p>Filter URLs based on a text prefix.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from astel.filterers.filters import StartsWith\n&gt;&gt;&gt; domain_starts_with = StartsWith(\"domain\", \"example\")\n&gt;&gt;&gt; domain_starts_with.filter(ParsedUrl(domain=\"https://example.com\", ...))  # True\n</code></pre> Source code in <code>astel/filters.py</code> <pre><code>class StartsWith(TextFilter):\n    \"\"\"Filter URLs based on a text prefix.\n\n    Examples:\n        &gt;&gt;&gt; from astel.filterers.filters import StartsWith\n        &gt;&gt;&gt; domain_starts_with = StartsWith(\"domain\", \"example\")\n        &gt;&gt;&gt; domain_starts_with.filter(ParsedUrl(domain=\"https://example.com\", ...))  # True\n    \"\"\"  # noqa: E501\n\n    def _apply(self, url: Url) -&gt; bool:\n        return self._get_url_property(url).startswith(self.text)\n</code></pre>"},{"location":"api/#astel.filters.TextFilter","title":"<code>TextFilter</code>","text":"<p>             Bases: <code>Filter[str]</code>, <code>ABC</code></p> <p>Base class for text filters.</p> <p>Filters URLs based on a text value.</p> Source code in <code>astel/filters.py</code> <pre><code>class TextFilter(Filter[str], ABC):\n    \"\"\"Base class for text filters.\n\n    Filters URLs based on a text value.\n    \"\"\"\n\n    def __init__(\n        self, url_prop: UrlProperty, text: str, *, case_sensitive: bool = True, **kwargs\n    ) -&gt; None:\n        super().__init__(url_prop, **kwargs)\n        self.case_sensitive = case_sensitive\n        if not self.case_sensitive:\n            text = text.lower()\n        self.text = text\n\n    def _get_url_property(self, url: Url) -&gt; str:\n        return (\n            super()._get_url_property(url)\n            if self.case_sensitive\n            else super()._get_url_property(url).lower()\n        )\n</code></pre>"},{"location":"api/#astel.filters.create_from_kwarg","title":"<code>create_from_kwarg(key, value)</code>","text":"<p>Create a filter from a key-value pair.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to create the filter from.</p> required <code>value</code> <code>FilterParameter</code> <p>The filter parameter.</p> required <p>Returns:</p> Type Description <code>Filter | None</code> <p>Filter | None: The created filter or None if the key is invalid.</p> Source code in <code>astel/filters.py</code> <pre><code>def create_from_kwarg(key: str, value: T) -&gt; Filter | None:\n    \"\"\"Create a filter from a key-value pair.\n\n    Args:\n        key (str): The key to create the filter from.\n        value (FilterParameter): The filter parameter.\n\n    Returns:\n        Filter | None: The created filter or None if the key is invalid.\n    \"\"\"\n    url_prop, filter_key = key.split(\"__\")\n    filter_key = _validate_filter_key(filter_key)\n    url_prop = _validate_url_property(url_prop)\n\n    for klass in _get_filter_subclasses():\n        if klass.__name__.lower() == filter_key:\n            return klass(url_prop, value)\n        if klass.__name__.lower() == filter_key[1:]:\n            klass = cast(Type[TextFilter], klass)\n            if not isinstance(value, str):\n                msg = f\"Expected a string value for {klass.__name__} filter.\"\n                raise ValueError(msg)\n            modifier = filter_key[0]\n            return klass(url_prop, value, case_sensitive=modifier != \"i\")\n    return None\n</code></pre>"},{"location":"api/#astel.limiters","title":"<code>astel.limiters</code>","text":"<p>Rate limiting module.</p> <p>Most websites have rate limits to prevent abuse and to ensure that their servers.</p> <p>This module defines the rate limiters that can be used to limit the amount of requests sent to a website.</p>"},{"location":"api/#astel.limiters.NoLimitRateLimiter","title":"<code>NoLimitRateLimiter</code>","text":"<p>             Bases: <code>RateLimiter</code></p> <p>A limiter that does not limit the requests. Keep in mind that sending a lot of requests per second can result in throttling or even bans.</p> Source code in <code>astel/limiters.py</code> <pre><code>class NoLimitRateLimiter(RateLimiter):\n    \"\"\"\n    A limiter that does not limit the requests. Keep in mind that sending a\n    lot of requests per second can result in throttling or even bans.\n    \"\"\"\n\n    async def limit(self) -&gt; None:  # type: ignore[override]\n        \"\"\"\n        Asynchronously sleeps for 0 seconds.\n        \"\"\"\n        await asyncio.sleep(0)\n\n    def configure(self, *args, **kwargs) -&gt; None:\n        \"\"\"\n        Does nothing\n        \"\"\"\n</code></pre>"},{"location":"api/#astel.limiters.NoLimitRateLimiter.configure","title":"<code>configure(*args, **kwargs)</code>","text":"<p>Does nothing</p> Source code in <code>astel/limiters.py</code> <pre><code>def configure(self, *args, **kwargs) -&gt; None:\n    \"\"\"\n    Does nothing\n    \"\"\"\n</code></pre>"},{"location":"api/#astel.limiters.NoLimitRateLimiter.limit","title":"<code>limit()</code>  <code>async</code>","text":"<p>Asynchronously sleeps for 0 seconds.</p> Source code in <code>astel/limiters.py</code> <pre><code>async def limit(self) -&gt; None:  # type: ignore[override]\n    \"\"\"\n    Asynchronously sleeps for 0 seconds.\n    \"\"\"\n    await asyncio.sleep(0)\n</code></pre>"},{"location":"api/#astel.limiters.PerDomainRateLimiter","title":"<code>PerDomainRateLimiter</code>","text":"<p>             Bases: <code>RateLimiter</code></p> <p>Limit the number of requests per domain using its especified limiter instance if given, otherwise uses the default limiter</p> Source code in <code>astel/limiters.py</code> <pre><code>class PerDomainRateLimiter(RateLimiter):\n    \"\"\"Limit the number of requests per domain using its especified\n    limiter instance if given, otherwise uses the default limiter\n    \"\"\"\n\n    default_limiter: RateLimiter | None = None\n    _domain_to_limiter: dict[str, RateLimiter]\n\n    def __init__(\n        self,\n        default_limiter: RateLimiter | None = None,\n    ) -&gt; None:\n        self.default_limiter = default_limiter\n        self._domain_to_limiter = {}\n\n    async def limit(self, url: str) -&gt; None:  # type: ignore[override]\n        \"\"\"Limit the requests to the given URL by its domain.\n\n        Args:\n            url (str): The URL to limit\n\n        Raises:\n            errors.InvalidConfigurationError: If no limiter is found for the domain.\n        \"\"\"\n        limiter = self._domain_to_limiter.get(\n            self.extract_domain(url), self.default_limiter\n        )\n        if limiter is None:\n            msg = \"No limiter found for the domain.\"\n            raise errors.InvalidConfigurationError(msg)\n\n        await limiter.limit()\n\n    def add_domain(self, domain: str, limiter: RateLimiter | None = None) -&gt; None:\n        \"\"\"Adds a new domain to the limited domains with an optional rate limiter.\n\n        Args:\n            domain (str): A string representing the domain name to add.\n            limiter (protocols.RateLimiter, optional): An optional `RateLimiter` instance used to limit the rate of requests to the domain. Defaults to None.\n\n        Raises:\n            errors.InvalidUrlError: If the given URL does not contain a valid domain.\n        \"\"\"  # noqa: E501\n        if limiter is None and self.default_limiter is None:\n            msg = \"No limiter was provided and no default limiter was set.\"\n            raise errors.InvalidConfigurationError(msg)\n\n        self._domain_to_limiter[domain] = cast(\n            RateLimiter, limiter or self.default_limiter\n        )\n\n    @staticmethod\n    def extract_domain(url: str) -&gt; str:\n        \"\"\"Extracts the domain from a given URL.\n\n        Returns:\n            str: A string representing the domain name extracted from the URL.\n        \"\"\"\n        return tldextract.extract(url).domain\n\n    def configure(self, config: RateLimiterConfig) -&gt; None:\n        \"\"\"Configures the rate at which requests are made to a domain by defining its\n        corresponding limiter.\n\n        Args:\n            config (RateLimiterConfig): The configuration to apply.\n\n        Raises:\n            errors.InvalidConfigurationError: If the new computed token rate is less than or equal to 0.\n        \"\"\"  # noqa: E501\n        if (\n            config[\"domain\"] is not None\n            and config[\"domain\"] not in self._domain_to_limiter\n        ):\n            self.add_domain(config[\"domain\"])\n            self._domain_to_limiter[config[\"domain\"]].configure(config)\n\n    @property\n    def domain_to_limiter(self) -&gt; dict[str, RateLimiter]:\n        return self._domain_to_limiter\n</code></pre>"},{"location":"api/#astel.limiters.PerDomainRateLimiter.add_domain","title":"<code>add_domain(domain, limiter=None)</code>","text":"<p>Adds a new domain to the limited domains with an optional rate limiter.</p> <p>Parameters:</p> Name Type Description Default <code>domain</code> <code>str</code> <p>A string representing the domain name to add.</p> required <code>limiter</code> <code>RateLimiter</code> <p>An optional <code>RateLimiter</code> instance used to limit the rate of requests to the domain. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>InvalidUrlError</code> <p>If the given URL does not contain a valid domain.</p> Source code in <code>astel/limiters.py</code> <pre><code>def add_domain(self, domain: str, limiter: RateLimiter | None = None) -&gt; None:\n    \"\"\"Adds a new domain to the limited domains with an optional rate limiter.\n\n    Args:\n        domain (str): A string representing the domain name to add.\n        limiter (protocols.RateLimiter, optional): An optional `RateLimiter` instance used to limit the rate of requests to the domain. Defaults to None.\n\n    Raises:\n        errors.InvalidUrlError: If the given URL does not contain a valid domain.\n    \"\"\"  # noqa: E501\n    if limiter is None and self.default_limiter is None:\n        msg = \"No limiter was provided and no default limiter was set.\"\n        raise errors.InvalidConfigurationError(msg)\n\n    self._domain_to_limiter[domain] = cast(\n        RateLimiter, limiter or self.default_limiter\n    )\n</code></pre>"},{"location":"api/#astel.limiters.PerDomainRateLimiter.configure","title":"<code>configure(config)</code>","text":"<p>Configures the rate at which requests are made to a domain by defining its corresponding limiter.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>RateLimiterConfig</code> <p>The configuration to apply.</p> required <p>Raises:</p> Type Description <code>InvalidConfigurationError</code> <p>If the new computed token rate is less than or equal to 0.</p> Source code in <code>astel/limiters.py</code> <pre><code>def configure(self, config: RateLimiterConfig) -&gt; None:\n    \"\"\"Configures the rate at which requests are made to a domain by defining its\n    corresponding limiter.\n\n    Args:\n        config (RateLimiterConfig): The configuration to apply.\n\n    Raises:\n        errors.InvalidConfigurationError: If the new computed token rate is less than or equal to 0.\n    \"\"\"  # noqa: E501\n    if (\n        config[\"domain\"] is not None\n        and config[\"domain\"] not in self._domain_to_limiter\n    ):\n        self.add_domain(config[\"domain\"])\n        self._domain_to_limiter[config[\"domain\"]].configure(config)\n</code></pre>"},{"location":"api/#astel.limiters.PerDomainRateLimiter.extract_domain","title":"<code>extract_domain(url)</code>  <code>staticmethod</code>","text":"<p>Extracts the domain from a given URL.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A string representing the domain name extracted from the URL.</p> Source code in <code>astel/limiters.py</code> <pre><code>@staticmethod\ndef extract_domain(url: str) -&gt; str:\n    \"\"\"Extracts the domain from a given URL.\n\n    Returns:\n        str: A string representing the domain name extracted from the URL.\n    \"\"\"\n    return tldextract.extract(url).domain\n</code></pre>"},{"location":"api/#astel.limiters.PerDomainRateLimiter.limit","title":"<code>limit(url)</code>  <code>async</code>","text":"<p>Limit the requests to the given URL by its domain.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to limit</p> required <p>Raises:</p> Type Description <code>InvalidConfigurationError</code> <p>If no limiter is found for the domain.</p> Source code in <code>astel/limiters.py</code> <pre><code>async def limit(self, url: str) -&gt; None:  # type: ignore[override]\n    \"\"\"Limit the requests to the given URL by its domain.\n\n    Args:\n        url (str): The URL to limit\n\n    Raises:\n        errors.InvalidConfigurationError: If no limiter is found for the domain.\n    \"\"\"\n    limiter = self._domain_to_limiter.get(\n        self.extract_domain(url), self.default_limiter\n    )\n    if limiter is None:\n        msg = \"No limiter found for the domain.\"\n        raise errors.InvalidConfigurationError(msg)\n\n    await limiter.limit()\n</code></pre>"},{"location":"api/#astel.limiters.RateLimiter","title":"<code>RateLimiter</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Base class for rate limiters.</p> Source code in <code>astel/limiters.py</code> <pre><code>class RateLimiter(ABC):\n    \"\"\"Base class for rate limiters.\"\"\"\n\n    @abstractmethod\n    def configure(\n        self,\n        config: RateLimiterConfig,\n    ) -&gt; None:\n        \"\"\"Configures the rate limiter to respect the rules defined by the domain with the given parameters.\n\n        In the case of a craw delay, the craw delay is ignored.\n\n        Args:\n            config (RateLimiterConfig): The configuration to apply.\n        \"\"\"  # noqa: E501\n        ...\n\n    @abstractmethod\n    async def limit(self, *args, **kwargs) -&gt; None:\n        \"\"\"Asynchronously limits the specified URL.\"\"\"\n        ...\n</code></pre>"},{"location":"api/#astel.limiters.RateLimiter.configure","title":"<code>configure(config)</code>  <code>abstractmethod</code>","text":"<p>Configures the rate limiter to respect the rules defined by the domain with the given parameters.</p> <p>In the case of a craw delay, the craw delay is ignored.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>RateLimiterConfig</code> <p>The configuration to apply.</p> required Source code in <code>astel/limiters.py</code> <pre><code>@abstractmethod\ndef configure(\n    self,\n    config: RateLimiterConfig,\n) -&gt; None:\n    \"\"\"Configures the rate limiter to respect the rules defined by the domain with the given parameters.\n\n    In the case of a craw delay, the craw delay is ignored.\n\n    Args:\n        config (RateLimiterConfig): The configuration to apply.\n    \"\"\"  # noqa: E501\n    ...\n</code></pre>"},{"location":"api/#astel.limiters.RateLimiter.limit","title":"<code>limit(*args, **kwargs)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Asynchronously limits the specified URL.</p> Source code in <code>astel/limiters.py</code> <pre><code>@abstractmethod\nasync def limit(self, *args, **kwargs) -&gt; None:\n    \"\"\"Asynchronously limits the specified URL.\"\"\"\n    ...\n</code></pre>"},{"location":"api/#astel.limiters.RateLimiterConfig","title":"<code>RateLimiterConfig</code>","text":"<p>             Bases: <code>TypedDict</code></p> <p>Rate limiting configuration.</p> <p>Attributes:</p> Name Type Description <code>domain</code> <code>str</code> <p>The domain to crawl.</p> <code>crawl_delay</code> <code>str</code> <p>A string representing the delay between each crawl in the format \"\" (as of the format used by request_rate (RequestRate): The rate at which to make requests. Source code in <code>astel/limiters.py</code> <pre><code>class RateLimiterConfig(TypedDict, total=False):\n    \"\"\"Rate limiting configuration.\n\n    Attributes:\n        domain (str): The domain to crawl.\n        crawl_delay (str, optional): A string representing the delay between each crawl in the format \"&lt;number&gt;&lt;unit&gt;\" (as of the format used by request_rate (RequestRate): The rate at which to make requests.\n    \"\"\"  # noqa: E501\n\n    domain: Optional[str]\n    crawl_delay: Optional[str]\n    request_rate: Optional[RequestRate]\n</code></pre>"},{"location":"api/#astel.limiters.StaticRateLimiter","title":"<code>StaticRateLimiter</code>","text":"<p>             Bases: <code>RateLimiter</code></p> <p>Limit the number of requests per second by waiting for a specified amount of time between requests</p> <p>Parameters:</p> Name Type Description Default <code>time_in_seconds</code> <code>float</code> <p>The amount of time to wait between requests</p> required Source code in <code>astel/limiters.py</code> <pre><code>class StaticRateLimiter(RateLimiter):\n    \"\"\"Limit the number of requests per second by waiting for a\n    specified amount of time between requests\n\n    Args:\n        time_in_seconds (float): The amount of time to wait between requests\n    \"\"\"\n\n    def __init__(self, time_in_seconds: float) -&gt; None:\n        self.time = time_in_seconds\n\n    async def limit(self) -&gt; None:  # type: ignore[override]\n        \"\"\"Limit by wainting for the specified amount of time\"\"\"\n        await asyncio.sleep(self.time)\n\n    def configure(\n        self,\n        config: RateLimiterConfig,\n    ) -&gt; None:\n        new_request_delay: Optional[float] = None\n        if craw_delay := config.get(\"crawl_delay\", None):\n            new_request_delay = float(craw_delay)\n        elif request_rate := config.get(\"request_rate\", None):\n            new_request_delay = request_rate.seconds / request_rate.requests\n\n        if new_request_delay and new_request_delay &lt; 0:\n            msg = \"The new request delay must be greater \"\n            \"than 0 (got {new_request_delay}).\"\n            raise errors.InvalidConfigurationError(msg)\n\n        # Use the greater of the two in order to respect all the domains\n        if new_request_delay and new_request_delay &gt; self.time:\n            self.time = new_request_delay\n</code></pre>"},{"location":"api/#astel.limiters.StaticRateLimiter.limit","title":"<code>limit()</code>  <code>async</code>","text":"<p>Limit by wainting for the specified amount of time</p> Source code in <code>astel/limiters.py</code> <pre><code>async def limit(self) -&gt; None:  # type: ignore[override]\n    \"\"\"Limit by wainting for the specified amount of time\"\"\"\n    await asyncio.sleep(self.time)\n</code></pre>"},{"location":"api/#astel.limiters.TokenBucketRateLimiter","title":"<code>TokenBucketRateLimiter</code>","text":"<p>             Bases: <code>RateLimiter</code></p> <p>Limit the requests by using the token bucket algorithm</p> <p>Parameters:</p> Name Type Description Default <code>tokens_per_second</code> <code>float</code> <p>The amount of tokens to add to the bucket per second.</p> required Source code in <code>astel/limiters.py</code> <pre><code>class TokenBucketRateLimiter(RateLimiter):\n    \"\"\"Limit the requests by using the token bucket algorithm\n\n    Args:\n        tokens_per_second (float): The amount of tokens to add to the bucket per second.\n    \"\"\"\n\n    __slots__ = (\"_tokens_per_second\", \"_tokens\", \"_last_refresh_time\")\n\n    def __init__(self, tokens_per_second: float) -&gt; None:\n        if tokens_per_second &lt;= 0:\n            msg = \"tokens_per_second must be greater than 0\"\n            raise ValueError(msg)\n\n        self._tokens_per_second = tokens_per_second\n        self._tokens = 0.0\n        self._last_refresh_time = self.utcnow()\n\n    @staticmethod\n    def utcnow() -&gt; datetime:\n        return datetime.now(timezone.utc)\n\n    def _refresh_tokens(self) -&gt; None:\n        \"\"\"Refreshes the tokens in the bucket based on the time elapsed since\n        the last refresh\n        \"\"\"\n        current_time = self.utcnow()\n        time_elapsed = current_time - self._last_refresh_time\n        new_tokens = time_elapsed.seconds * self._tokens_per_second\n        self._tokens = float(min(self._tokens + new_tokens, self._tokens_per_second))\n        self._last_refresh_time = current_time\n\n    def consume(self, tokens: int = 1) -&gt; bool:\n        \"\"\"Check if the given number of tokens can be consumed and decrease the\n        number of available tokens if possible.\n\n        Args:\n            tokens (int, optional): The number of tokens to consume. Default is 1.\n\n        Returns:\n            bool: `True` if the tokens were consumed, `False` otherwise\n        \"\"\"\n        self._refresh_tokens()\n        if self._tokens &gt;= tokens:\n            self._tokens -= tokens\n            return True\n        return False\n\n    async def limit(self) -&gt; None:  # type: ignore[override]\n        while not self.consume(1):\n            pass\n\n    @property\n    def tokens(self) -&gt; float:\n        self._refresh_tokens()\n        return self._tokens\n\n    @property\n    def tokens_per_second(self) -&gt; float:\n        return self._tokens_per_second\n\n    @property\n    def last_refresh_time(self) -&gt; datetime:\n        return self._last_refresh_time\n\n    def configure(\n        self,\n        config: RateLimiterConfig,\n    ) -&gt; None:\n        \"\"\"Configures the rate at which requests are made to a domain by setting the\n        tokens per second.\n        \"\"\"\n        if config[\"crawl_delay\"] is not None:\n            new_token_rate = 1 / int(config[\"crawl_delay\"])\n        elif config[\"request_rate\"] is not None:\n            new_token_rate = (\n                config[\"request_rate\"].requests / config[\"request_rate\"].seconds\n            )\n        else:\n            return\n\n        if new_token_rate &lt; 0:\n            msg = f\"The new token rate must be greater than 0 (got {new_token_rate}).\"\n            raise errors.InvalidConfigurationError(msg)\n\n        if new_token_rate &lt; self._tokens_per_second:\n            self._tokens_per_second = new_token_rate\n</code></pre>"},{"location":"api/#astel.limiters.TokenBucketRateLimiter.configure","title":"<code>configure(config)</code>","text":"<p>Configures the rate at which requests are made to a domain by setting the tokens per second.</p> Source code in <code>astel/limiters.py</code> <pre><code>def configure(\n    self,\n    config: RateLimiterConfig,\n) -&gt; None:\n    \"\"\"Configures the rate at which requests are made to a domain by setting the\n    tokens per second.\n    \"\"\"\n    if config[\"crawl_delay\"] is not None:\n        new_token_rate = 1 / int(config[\"crawl_delay\"])\n    elif config[\"request_rate\"] is not None:\n        new_token_rate = (\n            config[\"request_rate\"].requests / config[\"request_rate\"].seconds\n        )\n    else:\n        return\n\n    if new_token_rate &lt; 0:\n        msg = f\"The new token rate must be greater than 0 (got {new_token_rate}).\"\n        raise errors.InvalidConfigurationError(msg)\n\n    if new_token_rate &lt; self._tokens_per_second:\n        self._tokens_per_second = new_token_rate\n</code></pre>"},{"location":"api/#astel.limiters.TokenBucketRateLimiter.consume","title":"<code>consume(tokens=1)</code>","text":"<p>Check if the given number of tokens can be consumed and decrease the number of available tokens if possible.</p> <p>Parameters:</p> Name Type Description Default <code>tokens</code> <code>int</code> <p>The number of tokens to consume. Default is 1.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p><code>True</code> if the tokens were consumed, <code>False</code> otherwise</p> Source code in <code>astel/limiters.py</code> <pre><code>def consume(self, tokens: int = 1) -&gt; bool:\n    \"\"\"Check if the given number of tokens can be consumed and decrease the\n    number of available tokens if possible.\n\n    Args:\n        tokens (int, optional): The number of tokens to consume. Default is 1.\n\n    Returns:\n        bool: `True` if the tokens were consumed, `False` otherwise\n    \"\"\"\n    self._refresh_tokens()\n    if self._tokens &gt;= tokens:\n        self._tokens -= tokens\n        return True\n    return False\n</code></pre>"},{"location":"api/#astel.options","title":"<code>astel.options</code>","text":"<p>Options module.</p> <p>This module defines the options that can be used to configure the crawlers behavior.</p>"},{"location":"api/#astel.options.CrawlerOptions","title":"<code>CrawlerOptions</code>","text":"<p>             Bases: <code>TypedDict</code></p> <p>Crawler options.</p> <p>Attributes:</p> Name Type Description <code>client</code> <code>AsyncClient</code> <p>An instance of <code>httpx.AsyncClient</code> to use for network requests.</p> <code>workers</code> <code>int</code> <p>The number of worker tasks to run in parallel.</p> <code>limit</code> <code>int</code> <p>The maximum number of pages to crawl.</p> <code>user_agent</code> <code>str</code> <p>The user agent to use for the requests.</p> <code>parser</code> <code>Parser</code> <p>The parser to use for parsing the content of the websites to extract links.</p> <code>rate_limiter</code> <code>RateLimiter</code> <p>The rate limiter to limit the number of requests sent per second.</p> <code>event_limiter_factory</code> <code>Callable[[], EventEmitter]</code> <p>A factory function to create an event limiter for the crawler.</p> <code>retry_for_status_codes</code> <code>list[int]</code> <p>A list of status codes for which the crawler should retry the request.</p> Source code in <code>astel/options.py</code> <pre><code>class CrawlerOptions(TypedDict, total=False):\n    \"\"\"Crawler options.\n\n    Attributes:\n        client (httpx.AsyncClient): An instance of `httpx.AsyncClient` to use for network requests.\n        workers (int): The number of worker tasks to run in parallel.\n        limit (int): The maximum number of pages to crawl.\n        user_agent (str): The user agent to use for the requests.\n        parser (parsers.Parser): The parser to use for parsing the content of the websites to extract links.\n        rate_limiter (limiters.RateLimiter): The rate limiter to limit the number of requests sent per second.\n        event_limiter_factory (Callable[[], events.EventEmitter]): A factory function to create an event limiter for the crawler.\n        retry_for_status_codes (list[int]): A list of status codes for which the crawler should retry the request.\n    \"\"\"  # noqa: E501\n\n    client: httpx.AsyncClient\n    workers: int\n    limit: int\n    user_agent: str\n    parser_class: Type[parsers.Parser]\n    rate_limiter: limiters.RateLimiter\n    event_emitter_factory: Callable[[], events.EventEmitter]\n    retry_for_status_codes: list[int]\n</code></pre>"},{"location":"api/#astel.options.RetryHandler","title":"<code>RetryHandler</code>","text":"<p>             Bases: <code>Protocol</code></p> <p>Callable that determines whether the crawler should retry the request.</p> Source code in <code>astel/options.py</code> <pre><code>class RetryHandler(Protocol):\n    \"\"\"Callable that determines whether the crawler should retry the request.\"\"\"\n\n    def __call__(\n        self, url: parsers.Url, response: Union[httpx.Response, None], crawler: Crawler\n    ) -&gt; bool: ...\n</code></pre>"},{"location":"api/#astel.options.merge_with_default_options","title":"<code>merge_with_default_options(options=None)</code>","text":"<p>Merge the given options with the default options.</p> <p>Parameters:</p> Name Type Description Default <code>options</code> <code>CrawlerOptions</code> <p>The options to merge.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>CrawlerOptions</code> <code>CrawlerOptions</code> <p>The merged options.</p> Source code in <code>astel/options.py</code> <pre><code>def merge_with_default_options(options: CrawlerOptions | None = None) -&gt; CrawlerOptions:\n    \"\"\"Merge the given options with the default options.\n\n    Args:\n        options (CrawlerOptions): The options to merge.\n\n    Returns:\n        CrawlerOptions: The merged options.\n    \"\"\"\n    return {**DEFAULT_OPTIONS, **(options or {})}  # type: ignore   # noqa: PGH003\n</code></pre>"},{"location":"api/#astel.parsers","title":"<code>astel.parsers</code>","text":"<p>Parsers for extracting links from webpages and sitemaps.</p> <p>This module defines the parsers that can be used to extract the links from the content of a webpage or a sitemap.</p>"},{"location":"api/#astel.parsers.BaseParser","title":"<code>BaseParser</code>","text":"<p>             Bases: <code>InitParserMixin</code>, <code>ABC</code></p> <p>Base class to be used for implementing new parser classes.</p> Source code in <code>astel/parsers.py</code> <pre><code>class BaseParser(InitParserMixin, ABC):\n    \"\"\"Base class to be used for implementing new parser classes.\"\"\"\n</code></pre>"},{"location":"api/#astel.parsers.HTMLAnchorsParser","title":"<code>HTMLAnchorsParser</code>","text":"<p>             Bases: <code>InitParserMixin</code>, <code>HTMLParser</code></p> <p>A parser that extracts the urls from a webpage and filter them out with the given filterer.</p> <p>Parameters:</p> Name Type Description Default <code>base</code> <code>str</code> <p>The base URL to use to resolve relative URLs</p> <code>None</code> Source code in <code>astel/parsers.py</code> <pre><code>class HTMLAnchorsParser(InitParserMixin, HTMLParser):\n    \"\"\"A parser that extracts the urls from a webpage and filter them out with the\n    given filterer.\n\n    Args:\n        base (str): The base URL to use to resolve relative URLs\n    \"\"\"\n\n    @override\n    def handle_starttag(self, tag: str, attrs: list[tuple[str, str | None]]) -&gt; None:\n        if tag != \"a\":\n            return\n\n        for attr, value in attrs:\n            if attr == \"href\" and isinstance(value, str):\n                self.found_links.add(parse_url(value, self.base))\n</code></pre>"},{"location":"api/#astel.parsers.InitParserMixin","title":"<code>InitParserMixin</code>","text":"<p>Helper mixin to initialize the parser with a base URL.</p> Source code in <code>astel/parsers.py</code> <pre><code>class InitParserMixin:\n    \"\"\"Helper mixin to initialize the parser with a base URL.\"\"\"\n\n    def __init__(self, base: str | None = None) -&gt; None:\n        self.base = base\n        self.found_links: Set[Url] = set()\n        super().__init__()\n\n    def reset(self, base: str | None = None) -&gt; None:\n        if base is not None:\n            self.base = base\n        self.found_links.clear()\n        getattr(super(), \"reset\", lambda: ...)()\n</code></pre>"},{"location":"api/#astel.parsers.Parser","title":"<code>Parser</code>","text":"<p>             Bases: <code>Protocol</code></p> <p>Parses the content of a file (webpages, or sitemaps, for example) to extract the links of interest.</p> <p>Parameters:</p> Name Type Description Default <code>base</code> <code>Union[str, None]</code> <p>The base URL to use to resolve relative URLs. Defaults to <code>None</code>.</p> <code>None</code> Source code in <code>astel/parsers.py</code> <pre><code>class Parser(Protocol):\n    \"\"\"Parses the content of a file (webpages, or sitemaps, for example) to extract the links of interest.\n\n    Args:\n        base (Union[str, None]): The base URL to use to resolve relative URLs. Defaults to `None`.\n    \"\"\"  # noqa: E501\n\n    def __init__(self, base: str | None = None) -&gt; None: ...\n\n    def feed(self, text: str) -&gt; None:\n        \"\"\"Process the content of a website and update the `found_links` attribute\n\n        Args:\n            text (str): The content of the website\n        \"\"\"\n        ...\n\n    def reset(self, base: str | None = None) -&gt; None:\n        \"\"\"Reset the parser to its initial state.\n\n        Args:\n            base (Union[str, None], optional): The base URL to use to resolve relative URLs. Defaults to `None`.\n        \"\"\"  # noqa: E501\n\n    @property\n    def base(self) -&gt; str | None: ...\n\n    @property\n    def found_links(self) -&gt; Set[Url]: ...\n</code></pre>"},{"location":"api/#astel.parsers.Parser.feed","title":"<code>feed(text)</code>","text":"<p>Process the content of a website and update the <code>found_links</code> attribute</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The content of the website</p> required Source code in <code>astel/parsers.py</code> <pre><code>def feed(self, text: str) -&gt; None:\n    \"\"\"Process the content of a website and update the `found_links` attribute\n\n    Args:\n        text (str): The content of the website\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/#astel.parsers.Parser.reset","title":"<code>reset(base=None)</code>","text":"<p>Reset the parser to its initial state.</p> <p>Parameters:</p> Name Type Description Default <code>base</code> <code>Union[str, None]</code> <p>The base URL to use to resolve relative URLs. Defaults to <code>None</code>.</p> <code>None</code> Source code in <code>astel/parsers.py</code> <pre><code>def reset(self, base: str | None = None) -&gt; None:\n    \"\"\"Reset the parser to its initial state.\n\n    Args:\n        base (Union[str, None], optional): The base URL to use to resolve relative URLs. Defaults to `None`.\n    \"\"\"  # noqa: E501\n</code></pre>"},{"location":"api/#astel.parsers.SiteMapParser","title":"<code>SiteMapParser</code>","text":"<p>             Bases: <code>InitParserMixin</code></p> <p>Parses a sitemap file to extract the links of interest.</p> <p>Parameters:</p> Name Type Description Default <code>base</code> <code>str</code> <p>The base URL to use to resolve relative URLs</p> <code>None</code> Source code in <code>astel/parsers.py</code> <pre><code>class SiteMapParser(InitParserMixin):\n    \"\"\"Parses a sitemap file to extract the links of interest.\n\n    Args:\n        base (str): The base URL to use to resolve relative URLs\n    \"\"\"\n\n    def feed(self, text: str) -&gt; None:\n        root = ElementTree.fromstring(text)\n\n        for url_element in root.iter(\n            \"{http://www.sitemaps.org/schemas/sitemap/0.9}url\"\n        ):\n            loc_element = url_element.find(\n                \"{http://www.sitemaps.org/schemas/sitemap/0.9}loc\"\n            )\n            if loc_element is not None and loc_element.text:\n                self.found_links.add(parse_url(loc_element.text))\n</code></pre>"},{"location":"api/#astel.parsers.Url","title":"<code>Url</code>","text":"<p>             Bases: <code>Protocol</code></p> <p>Model of a URL for the library to work with.</p> Source code in <code>astel/parsers.py</code> <pre><code>class Url(Protocol):\n    \"\"\"\n    Model of a URL for the library to work with.\n    \"\"\"\n\n    @property\n    def domain(self) -&gt; str: ...\n\n    @property\n    def path(self) -&gt; str: ...\n\n    @property\n    def params(self) -&gt; str: ...\n\n    @property\n    def scheme(self) -&gt; str: ...\n\n    @property\n    def query(self) -&gt; str: ...\n\n    @property\n    def fragment(self) -&gt; str: ...\n\n    @property\n    def raw(self) -&gt; str: ...\n\n    @property\n    def filetype(self) -&gt; str: ...\n</code></pre>"},{"location":"api/#astel.parsers.parse_url","title":"<code>parse_url(url, base=None)</code>","text":"<p>Parse a URL into its components.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to parse</p> required <code>base</code> <code>str</code> <p>The base URL to use to resolve relative URLs. Defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Url</code> <code>Url</code> <p>The parsed URL</p> Source code in <code>astel/parsers.py</code> <pre><code>def parse_url(url: str, base: str | None = None) -&gt; Url:\n    \"\"\"Parse a URL into its components.\n\n    Args:\n        url (str): The URL to parse\n        base (str, optional): The base URL to use to resolve relative URLs. Defaults to `None`.\n\n    Returns:\n        Url: The parsed URL\n    \"\"\"  # noqa: E501\n    result = parse.urlparse(url if base is None else parse.urljoin(base, url))\n    return ParsedUrl(\n        result.scheme,\n        result.netloc,\n        result.path,\n        result.params,\n        result.query,\n        result.fragment,\n    )\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":""},{"location":"changelog/#010---2023-11-11","title":"[0.1.0] - 2023-11-11","text":"<ul> <li>First release on PyPI.</li> </ul>"},{"location":"cli/","title":"CLI","text":""},{"location":"cli/#cli","title":"CLI","text":"<p>Astel also includes a simple command line interface to execute a crawler with a initial set of URLs and see the pages found.</p> <pre><code>astel --help\n</code></pre> <pre><code>Usage: astel [OPTIONS] URLS...\n\n  Console script for astel.\n\nOptions:\n  -w, --workers INTEGER  Number of workers to use.  [default: 5]\n  -l, --limit INTEGER    Maximum number of URLs to crawl.  [default: 20]\n  -u, --agent TEXT       User agent to use for the requests.  [default: astel]\n  --help                 Show this message and exit.\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at the issues page.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>Astel could always use more documentation, whether as part of the official Astel docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at the issues feedback page.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions   are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started","text":"<p>Ready to contribute? Here's how to set up <code>astel</code> for local development.</p> <ol> <li>Fork the <code>astel</code> repo on GitHub.</li> <li> <p>Clone your fork locally</p> <pre><code>git clone git@github.com:your_name_here/astel.git\n</code></pre> </li> <li> <p>Ensure poetry is installed.</p> </li> <li> <p>Install dependencies and start your virtualenv:</p> <pre><code>poetry install -E test -E doc -E dev\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass the    tests, including testing other Python versions, with tox:</p> <pre><code>poetry run tox\n</code></pre> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>git add .\ngit commit -m \"Your detailed description of your changes.\"\ngit push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated. Put    your new functionality into a function with a docstring, and add the    feature to the list in README.md.</li> <li>The pull request should work for Python 3.6, 3.7, 3.8 and 3.9. Check    https://github.com/William-Fernandes252/astel/actions    and make sure that the tests pass for all supported Python versions.</li> </ol>"},{"location":"contributing/#tips","title":"Tips","text":"<pre><code>poetry run pytest tests/test_crawler.py\n</code></pre> <p>To run a subset of tests.</p>"},{"location":"contributing/#deploying","title":"Deploying","text":"<p>A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in CHANGELOG.md). Then run:</p> <pre><code>poetry run bump2version patch # possible: major / minor / patch\ngit push\ngit push --tags\n</code></pre> <p>GitHub Actions will then deploy to PyPI if tests pass.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#installation","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install Astel, run this command in your terminal:</p> <pre><code>pip install astel\n</code></pre> <p>This is the preferred method to install Astel, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-source","title":"From source","text":"<p>The source for Astel can be downloaded from the Github repo.</p> <p>You can either clone the public repository:</p> <pre><code>git clone git://github.com/William-Fernandes252/astel\n</code></pre> <p>Or download the tarball:</p> <pre><code>curl -OJL https://github.com/William-Fernandes252/astel/tarball/master\n</code></pre> <p>Once you have a copy of the source, you can install it with:</p> <pre><code>pip install .\n</code></pre>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#usage","title":"Usage","text":"<p>To use Astel in a project, simply create a crawler instance passing a set of URLs to start.</p> <pre><code>import asyncio\nimport astel\n\nasync def main():\n    crawler = Crawler([\"https://example.com\"])\n    crawler.run()\n    print(crawler.urls_seen)\n    # {ParsedUrl(domain='example', scheme='https', ...)}\n\nif __name__ == '__main__':\n    asyncio.run(main())\n</code></pre> <p>Note that the all the crawler operations are asyncronous, so you need to use a package that can run corotines like the built-in <code>asyncio</code> Python module.</p> <p>To get details on how you can configure and customize the crawler behavior, go to the API Reference.</p>"}]}